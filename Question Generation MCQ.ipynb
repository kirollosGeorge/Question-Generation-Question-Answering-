{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100c72ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kerillos\\anaconda3\\envs\\gpu\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Kerillos\\anaconda3\\envs\\gpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Kerillos\\anaconda3\\envs\\gpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.xwydx2ikjw2nmtwsfyngfuwkqu3lytcz.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Kerillos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "import random\n",
    "import spacy\n",
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "from sense2vec import Sense2Vec\n",
    "import requests\n",
    "from collections import OrderedDict\n",
    "import string\n",
    "import pke\n",
    "import nltk\n",
    "import numpy \n",
    "from nltk import FreqDist\n",
    "nltk.download('brown')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('popular')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from flashtext import KeywordProcessor\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "import unicodedata\n",
    "import html\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6febfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d82c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCQs_available(word,s2v):\n",
    "    word = word.replace(\" \", \"_\")\n",
    "    sense = s2v.get_best_sense(word)\n",
    "    if sense is not None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4e90a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sense2vec_get_words(word,s2v):\n",
    "    output = []\n",
    "\n",
    "    word_preprocessed =  word.translate(word.maketrans(\"\",\"\", string.punctuation))\n",
    "    word_preprocessed = word_preprocessed.lower()\n",
    "\n",
    "    word_edits = edits(word_preprocessed)\n",
    "\n",
    "    word = word.replace(\" \", \"_\")\n",
    "\n",
    "    sense = s2v.get_best_sense(word)\n",
    "    most_similar = s2v.most_similar(sense, n=15)\n",
    "\n",
    "    compare_list = [word_preprocessed]\n",
    "    for each_word in most_similar:\n",
    "        append_word = each_word[0].split(\"|\")[0].replace(\"_\", \" \")\n",
    "        append_word = append_word.strip()\n",
    "        append_word_processed = append_word.lower()\n",
    "        append_word_processed = append_word_processed.translate(append_word_processed.maketrans(\"\",\"\", string.punctuation))\n",
    "        if append_word_processed not in compare_list and word_preprocessed not in append_word_processed and append_word_processed not in word_edits:\n",
    "            output.append(append_word.title())\n",
    "            compare_list.append(append_word_processed)\n",
    "\n",
    "\n",
    "    out = list(OrderedDict.fromkeys(output))\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a2265ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_options(answer,s2v):\n",
    "    distractors =[]\n",
    "\n",
    "    try:\n",
    "        distractors = sense2vec_get_words(answer,s2v)\n",
    "        if len(distractors) > 0:\n",
    "            print(\" Sense2vec_distractors successful for word : \", answer)\n",
    "            return distractors,\"sense2vec\"\n",
    "    except:\n",
    "        print (\" Sense2vec_distractors failed for word : \",answer)\n",
    "\n",
    "\n",
    "    return distractors,\"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9935f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "    sentences = [sent_tokenize(text)]\n",
    "    sentences = [y for x in sentences for y in x]\n",
    "    # Remove any short sentences less than 20 letters.\n",
    "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82449de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_for_keyword(keywords, sentences):\n",
    "    keyword_processor = KeywordProcessor()\n",
    "    keyword_sentences = {}\n",
    "    for word in keywords:\n",
    "        word = word.strip()\n",
    "        keyword_sentences[word] = []\n",
    "        keyword_processor.add_keyword(word)\n",
    "    for sentence in sentences:\n",
    "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
    "        for key in keywords_found:\n",
    "            keyword_sentences[key].append(sentence)\n",
    "\n",
    "    for key in keyword_sentences.keys():\n",
    "        values = keyword_sentences[key]\n",
    "        values = sorted(values, key=len, reverse=True)\n",
    "        keyword_sentences[key] = values\n",
    "\n",
    "    delete_keys = []\n",
    "    for k in keyword_sentences.keys():\n",
    "        if len(keyword_sentences[k]) == 0:\n",
    "            delete_keys.append(k)\n",
    "    for del_key in delete_keys:\n",
    "        del keyword_sentences[del_key]\n",
    "\n",
    "    return keyword_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22747b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_far(words_list,currentword,thresh,normalized_levenshtein):\n",
    "    threshold = thresh\n",
    "    score_list =[]\n",
    "    for word in words_list:\n",
    "        score_list.append(Levenshtein.distance(word.lower(),currentword.lower()))\n",
    "    if min(score_list)>=threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51523127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_phrases(phrase_keys,max,normalized_levenshtein ):\n",
    "    filtered_phrases =[]\n",
    "    if len(phrase_keys)>0:\n",
    "        filtered_phrases.append(phrase_keys[0])\n",
    "        for ph in phrase_keys[1:]:\n",
    "            if is_far(filtered_phrases,ph,0.7,normalized_levenshtein ):\n",
    "                filtered_phrases.append(ph)\n",
    "            if len(filtered_phrases)>=max:\n",
    "                break\n",
    "    return filtered_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec747d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns_multipartite(text):\n",
    "    out = []\n",
    "\n",
    "    extractor = pke.unsupervised.MultipartiteRank()\n",
    "    extractor.load_document(input=text, language='en')\n",
    "    pos = {'PROPN', 'NOUN'}\n",
    "    stoplist = list(string.punctuation)\n",
    "    stoplist += stopwords.words('english')\n",
    "    extractor.candidate_selection(pos=pos)\n",
    "    # 4. build the Multipartite graph and rank candidates using random walk,\n",
    "    #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
    "    #    threshold/method parameters.\n",
    "    try:\n",
    "        extractor.candidate_weighting(alpha=1.1,\n",
    "                                      threshold=0.75,\n",
    "                                      method='average')\n",
    "    except:\n",
    "        return out\n",
    "\n",
    "    keyphrases = extractor.get_n_best(n=10)\n",
    "\n",
    "    for key in keyphrases:\n",
    "        out.append(key[0])\n",
    "\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f813ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrases(doc):\n",
    "    phrases={}\n",
    "    for np in doc.noun_chunks:\n",
    "        phrase =np.text\n",
    "        len_phrase = len(phrase.split())\n",
    "        if len_phrase > 1:\n",
    "            if phrase not in phrases:\n",
    "                phrases[phrase]=1\n",
    "            else:\n",
    "                phrases[phrase]=phrases[phrase]+1\n",
    "\n",
    "    phrase_keys=list(phrases.keys())\n",
    "    phrase_keys = sorted(phrase_keys, key= lambda x: len(x),reverse=True)\n",
    "    phrase_keys=phrase_keys[:50]\n",
    "    return phrase_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34269c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(nlp,text,max_keywords,s2v,fdist,normalized_levenshtein,no_of_sentences):\n",
    "    doc = nlp(text)\n",
    "    max_keywords = int(max_keywords)\n",
    "\n",
    "    keywords = get_nouns_multipartite(text)\n",
    "    keywords = sorted(keywords, key=lambda x: fdist[x])\n",
    "    keywords = filter_phrases(keywords, max_keywords,normalized_levenshtein )\n",
    "\n",
    "    phrase_keys = get_phrases(doc)\n",
    "    filtered_phrases = filter_phrases(phrase_keys, max_keywords,normalized_levenshtein )\n",
    "\n",
    "    total_phrases = keywords + filtered_phrases\n",
    "\n",
    "    total_phrases_filtered = filter_phrases(total_phrases, min(max_keywords, 2*no_of_sentences),normalized_levenshtein )\n",
    "\n",
    "\n",
    "    answers = []\n",
    "    for answer in total_phrases_filtered:\n",
    "        if answer not in answers and MCQs_available(answer,s2v):\n",
    "            answers.append(answer)\n",
    "\n",
    "    answers = answers[:max_keywords]\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98286839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions_mcq(keyword_sent_mapping,device,tokenizer,model,sense2vec,normalized_levenshtein):\n",
    "    batch_text = []\n",
    "    answers = keyword_sent_mapping.keys()\n",
    "    for answer in answers:\n",
    "        txt = keyword_sent_mapping[answer]\n",
    "        context = \"context: \" + txt\n",
    "        text = context + \" \" + \"answer: \" + answer + \" </s>\"\n",
    "        batch_text.append(text)\n",
    "\n",
    "    encoding = tokenizer.batch_encode_plus(batch_text, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "    print (\"Running model for generation\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outs = model.generate(input_ids=input_ids,\n",
    "                              attention_mask=attention_masks,\n",
    "                              max_length=150)\n",
    "\n",
    "    output_array ={}\n",
    "    output_array[\"questions\"] =[]\n",
    "#     print(outs)\n",
    "    for index, val in enumerate(answers):\n",
    "        individual_question ={}\n",
    "        out = outs[index, :]\n",
    "        dec = tokenizer.decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "        Question = dec.replace(\"question:\", \"\")\n",
    "        Question = Question.strip()\n",
    "        individual_question[\"question_statement\"] = Question\n",
    "        individual_question[\"question_type\"] = \"MCQ\"\n",
    "        individual_question[\"answer\"] = val\n",
    "        individual_question[\"id\"] = index+1\n",
    "        individual_question[\"options\"], individual_question[\"options_algorithm\"] = get_options(val, sense2vec)\n",
    "\n",
    "        individual_question[\"options\"] =  filter_phrases(individual_question[\"options\"], 10,normalized_levenshtein)\n",
    "        index = 3\n",
    "        individual_question[\"extra_options\"]= individual_question[\"options\"][index:]\n",
    "        individual_question[\"options\"] = individual_question[\"options\"][:index]\n",
    "        individual_question[\"context\"] = keyword_sent_mapping[val]\n",
    "     \n",
    "        if len(individual_question[\"options\"])>0:\n",
    "            output_array[\"questions\"].append(individual_question)\n",
    "\n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cc797e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_normal_questions(keyword_sent_mapping,device,tokenizer,model):  #for normal one word questions\n",
    "    batch_text = []\n",
    "    answers = keyword_sent_mapping.keys()\n",
    "    for answer in answers:\n",
    "        txt = keyword_sent_mapping[answer]\n",
    "        context = \"context: \" + txt\n",
    "        text = context + \" \" + \"answer: \" + answer + \" </s>\"\n",
    "        batch_text.append(text)\n",
    "\n",
    "    encoding = tokenizer.batch_encode_plus(batch_text, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "    print (\"Running model for generation\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outs = model.generate(input_ids=input_ids,\n",
    "                              attention_mask=attention_masks,\n",
    "                              max_length=150)\n",
    "\n",
    "    output_array ={}\n",
    "    output_array[\"questions\"] =[]\n",
    "    \n",
    "    for index, val in enumerate(answers):\n",
    "        individual_quest= {}\n",
    "        out = outs[index, :]\n",
    "        dec = tokenizer.decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        \n",
    "        Question= dec.replace('question:', '')\n",
    "        Question= Question.strip()\n",
    "\n",
    "        individual_quest['Question']= Question\n",
    "        individual_quest['Answer']= val\n",
    "        individual_quest[\"id\"] = index+1\n",
    "        individual_quest[\"context\"] = keyword_sent_mapping[val]\n",
    "        \n",
    "        output_array[\"questions\"].append(individual_quest)\n",
    "        \n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85603001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def edits(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz '+string.punctuation\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "def random_choice():\n",
    "    a = random.choice([0,1])\n",
    "    return bool(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1822b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mcq(payload):\n",
    "        start = time.time()\n",
    "        inp = {\n",
    "            \"input_text\": payload.get(\"input_text\"),\n",
    "            \"max_questions\": payload.get(\"max_questions\", 15)\n",
    "        }\n",
    "\n",
    "        text = inp['input_text']\n",
    "        sentences = tokenize_sentences(text)\n",
    "        joiner = \" \"\n",
    "        modified_text = joiner.join(sentences)\n",
    "\n",
    "\n",
    "        keywords = get_keywords(nlp,modified_text,inp['max_questions'],s2v,fdist,normalized_levenshtein,len(sentences) )\n",
    "\n",
    "\n",
    "        keyword_sentence_mapping = get_sentences_for_keyword(keywords, sentences)\n",
    "\n",
    "        for k in keyword_sentence_mapping.keys():\n",
    "            text_snippet = \" \".join(keyword_sentence_mapping[k][:3])\n",
    "            keyword_sentence_mapping[k] = text_snippet\n",
    "\n",
    "   \n",
    "        final_output = {}\n",
    "\n",
    "        if len(keyword_sentence_mapping.keys()) == 0:\n",
    "            return final_output\n",
    "        else:\n",
    "            try:\n",
    "                generated_questions = generate_questions_mcq(keyword_sentence_mapping,device,tokenizer,model,s2v,normalized_levenshtein)\n",
    "\n",
    "            except:\n",
    "                return final_output\n",
    "            end = time.time()\n",
    "\n",
    "            final_output[\"statement\"] = modified_text\n",
    "            final_output[\"questions\"] = generated_questions[\"questions\"]\n",
    "            final_output[\"time_taken\"] = end-start\n",
    "            \n",
    "            if torch.device=='cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ad5ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_tags(text):\n",
    "    # Remove tags\n",
    "    return re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    re1 = re.compile(r'  +')\n",
    "    x1 = text.lower().replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n",
    "        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x1))\n",
    "\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    \n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "def to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    list_pun = '!\"#$%&\\'()*-/:;<=>?@[\\\\]^_`{|}~'\n",
    "    translator = str.maketrans('', '', list_pun) ## , . +\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def replace_numbers(text):\n",
    "    \n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "\n",
    "def remove_whitespaces(text):\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def remove_stopwords(words, stop_words):\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "\n",
    "def stem_words(words):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "def lemmatize_words(words):\n",
    "    \n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(word, pos='v') for word in words])\n",
    "\n",
    "def text2words(text):\n",
    "  return word_tokenize(text)\n",
    "\n",
    "def normalize_text( text):\n",
    "    text = remove_special_chars(text)\n",
    "    text = remove_non_ascii(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = to_lowercase(text)\n",
    "    text = replace_numbers(text)\n",
    "    #words = text2words(text)\n",
    "    #words = remove_stopwords(words, stop_words)\n",
    "    #words = stem_words(words)# Either stem ovocar lemmatize\n",
    "    #words = lemmatize_words(words)\n",
    "    #words = lemmatize_verbs(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4471640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('Parth/result')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "device = device\n",
    "model = model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "s2v = Sense2Vec().from_disk('s2v_old')\n",
    "\n",
    "fdist = FreqDist(brown.words())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bac739d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_levenshtein = Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89aaa1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lionel Andrés Messi Born and raised in central Argentina, Messi relocated to Spain to join Barcelona at the age of 13, for whom he made his competitive debut aged 17 in October 2004. He established himself as an integral player for the club within the next three years, and in his first uninterrupted season in 2008–09 he helped Barcelona achieve the first treble in Spanish football; that year, aged 22, Messi won his first Ballon d\\'Or. Three successful seasons followed, with Messi winning four consecutive Ballons d\\'Or, making him the first player to win the award four times and in a row.[10] During the 2011–12 season, he set the La Liga and European records for most goals scored in a single season, while establishing himself as Barcelona\\'s all-time top scorer. The following two seasons, Messi finished second for the Ballon d\\'Or behind Cristiano Ronaldo (his perceived career rival), before regaining his best form during the 2014–15 campaign, becoming the all-time top scorer in La Liga and leading Barcelona to a historic second treble, after which he was awarded a fifth Ballon d\\'Or in 2015. Messi assumed captaincy of Barcelona in 2018, and in 2019 he won a record sixth Ballon d\\'Or. Out of contract, he signed for Paris Saint-Germain in August 2021\\nMessi has endorsed sportswear company Adidas since 2006. According to France Football, he was the world\\'s highest-paid footballer for five years out of six between 2009 and 2014, and was ranked the world\\'s highest-paid athlete by Forbes in 2019 and 2022.[11] Messi was among Time\\'s 100 most influential people in the world in 2011 and 2012. In February 2020, he was awarded the Laureus World Sportsman of the Year, thus becoming the first footballer and the first team sport athlete to win the award. Later that year, Messi became the second footballer (and second team-sport athlete) to surpass $1 billion in career earnings\\nMohamed Salah Hamed Mahrous Ghaly an Egyptian professional footballer who plays as a forward for Premier League club Liverpool and captains the Egypt national team. Considered one of the best players in the world and amongst the greatest African players of all time, he is known for his finishing, dribbling, and speed.\\nAt international level, Salah represented Egypt at youth level before making his senior debut in 2011. Following his performances at the 2012 Summer Olympics, he was named CAF Most Promising African Talent of the Year. Since then, he finished as runner-up in the 2017 and 2021 Africa Cup of Nations and was top scorer during CAF qualification as Egypt qualified for the 2018 FIFA World Cup. Salah was named CAF African Footballer of the Year (2017 and 2018), BBC African Footballer of the Year (2017 and 2018), and was selected in the 2017 Africa Cup of Nations Team of the Tournament, 2021 Africa Cup of Nations Team of the Tournament and the CAF Team of the Year on several occasions.\\nMachine learning Machine learning programs can perform tasks without being explicitly programmed to do so. It involves computers learning from data provided so that they carry out certain tasks. For simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand; on the computer\\'s part, no learning is needed. For more advanced tasks, it can be challenging for a human to manually create the needed algorithms. In practice, it can turn out to be more effective to help the machine develop its own algorithm, rather than having human programmers specify every needed step\\nArtificial intelligence As a scientific endeavor, machine learning grew out of the quest for artificial intelligence. In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what was then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics \\nData mining Machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods\\nOptimization is Machine learning also has intimate ties to optimization: many learning problems are formulated as minimization of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the pre-assigned labels of a set of examples)\\nDeep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised.\\nDeep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and Transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance\\nArtificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analogue\\nFootball is a family of team sports that involve, to varying degrees, kicking a ball to score a goal. Unqualified, the word football normally means the form of football that is the most popular where the word is used. Sports commonly called football include association football (known as soccer in North America and Oceania); gridiron football (specifically American football or Canadian football); Australian rules football; rugby union and rugby league; and Gaelic football.\\nThere are a number of references to traditional, ancient, or prehistoric ball games played in many different parts of the world.\\nContemporary codes of football can be traced back to the codification of these games at English public schools during the 19th century.\\nMedicine is the science and practice of caring for a patient, managing the diagnosis, prognosis, prevention, treatment, palliation of their injury or disease, and promoting their health. Medicine encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. Contemporary medicine applies biomedical sciences, biomedical research, genetics, and medical technology to diagnose, treat, and prevent injury and disease, typically through pharmaceuticals or surgery, but also through therapies as diverse as psychotherapy, external splints and traction, medical devices, biologics, and ionizing radiation, amongst others.\\nThe Amazon River in South America is the largest river by discharge volume of water in the world, and the disputed longest river system in the world in comparison to the Nile.\\nThe headwaters of the Apurímac River on Nevado Mismi had been considered for nearly a century as the Amazon basin most distant source, until a 2014 study found it to be the headwaters of the Mantaro River on the Cordillera Rumi Cruz in Peru.\\nThe Mantaro and Apurímac rivers join, and with other tributaries form the Ucayali River, which in turn meets the Marañón River upstream of Iquitos, Peru, forming what countries other than Brazil consider to be the main stem of the Amazon. Brazilians call this section the Solimões River above its confluence with the Rio Negro.\\nforming what Brazilians call the Amazon at the Meeting of Waters (Portuguese: Encontro das Águas) at Manaus, the largest city on the river.\\nThe Amazon was initially known by Europeans as the Marañón, and the Peruvian part of the river is still known by that name today. It later became known as Rio Amazonas in Spanish and Portuguese.Recent geological studies suggest that for millions of years the Amazon River used to flow in the opposite direction - from east to west. Eventually the Andes Mountains formed, blocking its flow to the Pacific Ocean, and causing it to switch directions to its current mouth in the Atlantic Ocean.\\nThe Nile  is a major north-flowing river in northeastern Africa. It flows into the Mediterranean Sea. The Nile is the longest river in Africa and has historically been considered the longest river in the world,though this has been contested by research suggesting that the Amazon River is slightly longer.\\nOf the world\\'s major rivers, the Nile is one of the smallest, as measured by annual flow in cubic metres of water.\\nIn particular, the Nile is the primary water source of Egypt, Sudan and South Sudan.\\nThe Nile has two major tributaries – the White Nile and the Blue Nile. The White Nile is traditionally considered to be the headwaters stream.\\nThe standard English names \"White Nile\" and \"Blue Nile\" refer to the river\\'s source, derived from Arabic names formerly applied to only the Sudanese stretches that meet at Khartoum.\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data.txt','r',encoding=\"UTF-8\") as f:\n",
    "    file = f.read()\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6553735a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lionel andres messi born and raised in central argentina, messi relocated to spain to join barcelona at the age of , for whom he made his competitive debut aged  in october . he established himself as an integral player for the club within the next three years, and in his first uninterrupted season in  he helped barcelona achieve the first treble in spanish football that year, aged , messi won his first ballon dor. three successful seasons followed, with messi winning four consecutive ballons dor, making him the first player to win the award four times and in a row. during the  season, he set the la liga and european records for most goals scored in a single season, while establishing himself as barcelonas alltime top scorer. the following two seasons, messi finished second for the ballon dor behind cristiano ronaldo his perceived career rival, before regaining his best form during the  campaign, becoming the alltime top scorer in la liga and leading barcelona to a historic second treble, after which he was awarded a fifth ballon dor in . messi assumed captaincy of barcelona in , and in  he won a record sixth ballon dor. out of contract, he signed for paris saintgermain in august \\nmessi has endorsed sportswear company adidas since . according to france football, he was the worlds highestpaid footballer for five years out of six between  and , and was ranked the worlds highestpaid athlete by forbes in  and . messi was among times  most influential people in the world in  and . in february , he was awarded the laureus world sportsman of the year, thus becoming the first footballer and the first team sport athlete to win the award. later that year, messi became the second footballer and second teamsport athlete to surpass  billion in career earnings\\nmohamed salah hamed mahrous ghaly an egyptian professional footballer who plays as a forward for premier league club liverpool and captains the egypt national team. considered one of the best players in the world and amongst the greatest african players of all time, he is known for his finishing, dribbling, and speed.\\nat international level, salah represented egypt at youth level before making his senior debut in . following his performances at the  summer olympics, he was named caf most promising african talent of the year. since then, he finished as runnerup in the  and  africa cup of nations and was top scorer during caf qualification as egypt qualified for the  fifa world cup. salah was named caf african footballer of the year  and , bbc african footballer of the year  and , and was selected in the  africa cup of nations team of the tournament,  africa cup of nations team of the tournament and the caf team of the year on several occasions.\\nmachine learning machine learning programs can perform tasks without being explicitly programmed to do so. it involves computers learning from data provided so that they carry out certain tasks. for simple tasks assigned to computers, it is possible to program algorithms telling the machine how to execute all steps required to solve the problem at hand on the computers part, no learning is needed. for more advanced tasks, it can be challenging for a human to manually create the needed algorithms. in practice, it can turn out to be more effective to help the machine develop its own algorithm, rather than having human programmers specify every needed step\\nartificial intelligence as a scientific endeavor, machine learning grew out of the quest for artificial intelligence. in the early days of ai as an academic discipline, some researchers were interested in having machines learn from data. they attempted to approach the problem with various symbolic methods, as well as what was then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics \\ndata mining machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases. data mining uses many machine learning methods\\noptimization is machine learning also has intimate ties to optimization many learning problems are formulated as minimization of some loss function on a training set of examples. loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the preassigned labels of a set of examples\\ndeep learning also known as deep structured learning is part of a broader family of machine learning methods based on artificial neural networks with representation learning. learning can be supervised, semisupervised or unsupervised.\\ndeeplearning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance\\nartificial neural networks anns were inspired by information processing and distributed communication nodes in biological systems. anns have various differences from biological brains. specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic plastic and analogue\\nfootball is a family of team sports that involve, to varying degrees, kicking a ball to score a goal. unqualified, the word football normally means the form of football that is the most popular where the word is used. sports commonly called football include association football known as soccer in north america and oceania gridiron football specifically american football or canadian football australian rules football rugby union and rugby league and gaelic football.\\nthere are a number of references to traditional, ancient, or prehistoric ball games played in many different parts of the world.\\ncontemporary codes of football can be traced back to the codification of these games at english public schools during the th century.\\nmedicine is the science and practice of caring for a patient, managing the diagnosis, prognosis, prevention, treatment, palliation of their injury or disease, and promoting their health. medicine encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. contemporary medicine applies biomedical sciences, biomedical research, genetics, and medical technology to diagnose, treat, and prevent injury and disease, typically through pharmaceuticals or surgery, but also through therapies as diverse as psychotherapy, external splints and traction, medical devices, biologics, and ionizing radiation, amongst others.\\nthe amazon river in south america is the largest river by discharge volume of water in the world, and the disputed longest river system in the world in comparison to the nile.\\nthe headwaters of the apurimac river on nevado mismi had been considered for nearly a century as the amazon basin most distant source, until a  study found it to be the headwaters of the mantaro river on the cordillera rumi cruz in peru.\\nthe mantaro and apurimac rivers join, and with other tributaries form the ucayali river, which in turn meets the maranon river upstream of iquitos, peru, forming what countries other than brazil consider to be the main stem of the amazon. brazilians call this section the solimoes river above its confluence with the rio negro.\\nforming what brazilians call the amazon at the meeting of waters portuguese encontro das aguas at manaus, the largest city on the river.\\nthe amazon was initially known by europeans as the maranon, and the peruvian part of the river is still known by that name today. it later became known as rio amazonas in spanish and portuguese.recent geological studies suggest that for millions of years the amazon river used to flow in the opposite direction  from east to west. eventually the andes mountains formed, blocking its flow to the pacific ocean, and causing it to switch directions to its current mouth in the atlantic ocean.\\nthe nile is a major northflowing river in northeastern africa. it flows into the mediterranean sea. the nile is the longest river in africa and has historically been considered the longest river in the world,though this has been contested by research suggesting that the amazon river is slightly longer.\\nof the worlds major rivers, the nile is one of the smallest, as measured by annual flow in cubic metres of water.\\nin particular, the nile is the primary water source of egypt, sudan and south sudan.\\nthe nile has two major tributaries  the white nile and the blue nile. the white nile is traditionally considered to be the headwaters stream.\\nthe standard english names white nile and blue nile refer to the rivers source, derived from arabic names formerly applied to only the sudanese stretches that meet at khartoum.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = normalize_text(file)\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8d67ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kerillos\\anaconda3\\envs\\gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kerillos\\anaconda3\\envs\\gpu\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:194: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model for generation\n",
      " Sense2vec_distractors successful for word :  amazon river\n",
      " Sense2vec_distractors successful for word :  messi\n",
      " Sense2vec_distractors successful for word :  worlds\n",
      " Sense2vec_distractors successful for word :  references\n",
      " Sense2vec_distractors successful for word :  football\n",
      " Sense2vec_distractors successful for word :  learning\n",
      " Sense2vec_distractors successful for word :  machine\n",
      " Sense2vec_distractors successful for word :  years\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"input_text\": file \n",
    "    \n",
    "}\n",
    "            \n",
    "            \n",
    "\n",
    "output = predict_mcq(payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15aa2521",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is :  the nile is the longest river in africa and has historically been considered the longest river in the world,though this has been contested by research suggesting that the amazon river is slightly longer. it later became known as rio amazonas in spanish and portuguese.recent geological studies suggest that for millions of years the amazon river used to flow in the opposite direction  from east to west. the amazon river in south america is the largest river by discharge volume of water in the world, and the disputed longest river system in the world in comparison to the nile.\n",
      "\n",
      "\n",
      "Question 1 - Which is the longest river in Africa?\n",
      "A- amazon river\n",
      "B- Atlantic Ocean\n",
      "C- Galapagos Islands\n",
      "D- Himalayas\n",
      "\n",
      "\n",
      "Answer is :  amazon river\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  the following two seasons, messi finished second for the ballon dor behind cristiano ronaldo his perceived career rival, before regaining his best form during the  campaign, becoming the alltime top scorer in la liga and leading barcelona to a historic second treble, after which he was awarded a fifth ballon dor in . later that year, messi became the second footballer and second teamsport athlete to surpass  billion in career earnings\n",
      "mohamed salah hamed mahrous ghaly an egyptian professional footballer who plays as a forward for premier league club liverpool and captains the egypt national team. he established himself as an integral player for the club within the next three years, and in his first uninterrupted season in  he helped barcelona achieve the first treble in spanish football that year, aged , messi won his first ballon dor.\n",
      "\n",
      "\n",
      "Question 2 - Who was the first player to win his first ballon dor?\n",
      "A- Ronaldo\n",
      "B- messi\n",
      "C- Neuer\n",
      "D- Neymar\n",
      "\n",
      "\n",
      "Answer is :  messi\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  according to france football, he was the worlds highestpaid footballer for five years out of six between  and , and was ranked the worlds highestpaid athlete by forbes in  and . according to france football, he was the worlds highestpaid footballer for five years out of six between  and , and was ranked the worlds highestpaid athlete by forbes in  and . of the worlds major rivers, the nile is one of the smallest, as measured by annual flow in cubic metres of water.\n",
      "\n",
      "\n",
      "Question 3 - How did he rank as the highest paid athlete in the world?\n",
      "A- worlds\n",
      "B- Main Regions\n",
      "C- Major Regions\n",
      "D- World Atm\n",
      "\n",
      "\n",
      "Answer is :  worlds\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  there are a number of references to traditional, ancient, or prehistoric ball games played in many different parts of the world.\n",
      "\n",
      "\n",
      "Question 4 - What are the references to traditional, ancient, or prehistoric ball games?\n",
      "A- references\n",
      "B- Source Materials\n",
      "C- Summaries\n",
      "D- Excerpts\n",
      "\n",
      "\n",
      "Answer is :  references\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic plastic and analogue\n",
      "football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal. sports commonly called football include association football known as soccer in north america and oceania gridiron football specifically american football or canadian football australian rules football rugby union and rugby league and gaelic football. sports commonly called football include association football known as soccer in north america and oceania gridiron football specifically american football or canadian football australian rules football rugby union and rugby league and gaelic football.\n",
      "\n",
      "\n",
      "Question 5 - What is the most common sport in the world?\n",
      "A- Basketball\n",
      "B- Soccer\n",
      "C- Rugby\n",
      "D- football\n",
      "\n",
      "\n",
      "Answer is :  football\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  deeplearning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance\n",
      "artificial neural networks anns were inspired by information processing and distributed communication nodes in biological systems. they attempted to approach the problem with various symbolic methods, as well as what was then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics \n",
      "data mining machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases. they attempted to approach the problem with various symbolic methods, as well as what was then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics \n",
      "data mining machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases.\n",
      "\n",
      "\n",
      "Question 6 - What is the analysis step of knowledge discovery in databases?\n",
      "A- Basics\n",
      "B- learning\n",
      "C- Learn\n",
      "D- Learnt\n",
      "\n",
      "\n",
      "Answer is :  learning\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  deeplearning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance\n",
      "artificial neural networks anns were inspired by information processing and distributed communication nodes in biological systems. they attempted to approach the problem with various symbolic methods, as well as what was then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics \n",
      "data mining machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases. they attempted to approach the problem with various symbolic methods, as well as what was then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics \n",
      "data mining machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases.\n",
      "\n",
      "\n",
      "Question 7 - What type of learning focuses on prediction?\n",
      "A- Computer\n",
      "B- Workstation\n",
      "C- machine\n",
      "D- Appliance\n",
      "\n",
      "\n",
      "Answer is :  machine\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  he established himself as an integral player for the club within the next three years, and in his first uninterrupted season in  he helped barcelona achieve the first treble in spanish football that year, aged , messi won his first ballon dor. it later became known as rio amazonas in spanish and portuguese.recent geological studies suggest that for millions of years the amazon river used to flow in the opposite direction  from east to west. according to france football, he was the worlds highestpaid footballer for five years out of six between  and , and was ranked the worlds highestpaid athlete by forbes in  and .\n",
      "\n",
      "\n",
      "Question 8 - How long did Messi play for Barcelona?\n",
      "A- Decades\n",
      "B- Months\n",
      "C- Yrs\n",
      "D- years\n",
      "\n",
      "\n",
      "Answer is :  years\n",
      "____________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for n in output['questions']:\n",
    "    count = count+1\n",
    "    list_of_choose = n['options'] + [n['answer'] ]\n",
    "    sample_list = random.sample(list_of_choose,k=4)\n",
    "    print(\"Context is : \",n['context'])\n",
    "    print(\"\\n\")\n",
    "    print(f\"Question {count} - {n['question_statement']}\")\n",
    "    print(f\"A- {sample_list[0]}\")\n",
    "    print(f\"B- {sample_list[1]}\")\n",
    "    print(f\"C- {sample_list[2]}\")\n",
    "    print(f\"D- {sample_list[3]}\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Answer is : \",n['answer'])\n",
    "    print(\"__\"*62)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d033223",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00b6da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoding (inp_ids,attn_mask,model,tokenizer):\n",
    "        greedy_output = model.generate(input_ids=inp_ids, attention_mask=attn_mask, max_length=256)\n",
    "        Question =  tokenizer.decode(greedy_output[0], skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "        return Question.strip().capitalize()\n",
    "\n",
    "def predict_answer(self,payload):\n",
    "    start = time.time()\n",
    "    inp = {\n",
    "        \"input_text\": payload.get(\"input_text\"),\n",
    "        \"input_question\" : payload.get(\"input_question\")\n",
    "    }\n",
    "\n",
    "    context = inp[\"input_text\"]\n",
    "    question = inp[\"input_question\"]\n",
    "    input = \"question: %s <s> context: %s </s>\" % (question,context)\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(input, return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(self.device), encoding[\"attention_mask\"].to(self.device)\n",
    "    greedy_output = self.model.generate(input_ids=input_ids, attention_mask=attention_masks, max_length=256)\n",
    "    Question =  self.tokenizer.decode(greedy_output[0], skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    output = Question.strip().capitalize()\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acbc4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('model-QA/')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# model.eval()\n",
    "device = device\n",
    "model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f5a34e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is :  the nile is the longest river in africa and has historically been considered the longest river in the world,though this has been contested by research suggesting that the amazon river is slightly longer. it later became known as rio amazonas in spanish and portuguese.recent geological studies suggest that for millions of years the amazon river used to flow in the opposite direction  from east to west. the amazon river in south america is the largest river by discharge volume of water in the world, and the disputed longest river system in the world in comparison to the nile.\n",
      "\n",
      "\n",
      "Question 1 - Which is the longest river in Africa?\n",
      "\n",
      "\n",
      "Answer is :  The nile\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  the following two seasons, messi finished second for the ballon dor behind cristiano ronaldo his perceived career rival, before regaining his best form during the  campaign, becoming the alltime top scorer in la liga and leading barcelona to a historic second treble, after which he was awarded a fifth ballon dor in . later that year, messi became the second footballer and second teamsport athlete to surpass  billion in career earnings\n",
      "mohamed salah hamed mahrous ghaly an egyptian professional footballer who plays as a forward for premier league club liverpool and captains the egypt national team. he established himself as an integral player for the club within the next three years, and in his first uninterrupted season in  he helped barcelona achieve the first treble in spanish football that year, aged , messi won his first ballon dor.\n",
      "\n",
      "\n",
      "Question 2 - Who was the first player to win his first ballon dor?\n",
      "\n",
      "\n",
      "Answer is :  Barcelona\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  according to france football, he was the worlds highestpaid footballer for five years out of six between  and , and was ranked the worlds highestpaid athlete by forbes in  and . according to france football, he was the worlds highestpaid footballer for five years out of six between  and , and was ranked the worlds highestpaid athlete by forbes in  and . of the worlds major rivers, the nile is one of the smallest, as measured by annual flow in cubic metres of water.\n",
      "\n",
      "\n",
      "Question 3 - How did he rank as the highest paid athlete in the world?\n",
      "\n",
      "\n",
      "Answer is :  He was the worlds highestpaid footballer for five years out of six between and, and was ranked the worlds highestpaid athlete by forbes in and.\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  there are a number of references to traditional, ancient, or prehistoric ball games played in many different parts of the world.\n",
      "\n",
      "\n",
      "Question 4 - What are the references to traditional, ancient, or prehistoric ball games?\n",
      "\n",
      "\n",
      "Answer is :  Traditional, ancient, or prehistoric ball games played in many different parts of the world.\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic plastic and analogue\n",
      "football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal. sports commonly called football include association football known as soccer in north america and oceania gridiron football specifically american football or canadian football australian rules football rugby union and rugby league and gaelic football. sports commonly called football include association football known as soccer in north america and oceania gridiron football specifically american football or canadian football australian rules football rugby union and rugby league and gaelic football.\n",
      "\n",
      "\n",
      "Question 5 - What is the most common sport in the world?\n",
      "\n",
      "\n",
      "Answer is :  Football\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  deeplearning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance\n",
      "artificial neural networks anns were inspired by information processing and distributed communication nodes in biological systems. they attempted to approach the problem with various symbolic methods, as well as what was then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics \n",
      "data mining machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases. they attempted to approach the problem with various symbolic methods, as well as what was then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics \n",
      "data mining machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases.\n",
      "\n",
      "\n",
      "Question 6 - What is the analysis step of knowledge discovery in databases?\n",
      "\n",
      "\n",
      "Answer is :  Deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance artificial neural networks anns were inspired by information processing and distributed communication nodes in biological systems.\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  deeplearning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance\n",
      "artificial neural networks anns were inspired by information processing and distributed communication nodes in biological systems. they attempted to approach the problem with various symbolic methods, as well as what was then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics \n",
      "data mining machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases. they attempted to approach the problem with various symbolic methods, as well as what was then termed neural networks these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics \n",
      "data mining machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of previously unknown properties in the data this is the analysis step of knowledge discovery in databases.\n",
      "\n",
      "\n",
      "Question 7 - What type of learning focuses on prediction?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer is :  Deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs.\n",
      "____________________________________________________________________________________________________________________________\n",
      "Context is :  he established himself as an integral player for the club within the next three years, and in his first uninterrupted season in  he helped barcelona achieve the first treble in spanish football that year, aged , messi won his first ballon dor. it later became known as rio amazonas in spanish and portuguese.recent geological studies suggest that for millions of years the amazon river used to flow in the opposite direction  from east to west. according to france football, he was the worlds highestpaid footballer for five years out of six between  and , and was ranked the worlds highestpaid athlete by forbes in  and .\n",
      "\n",
      "\n",
      "Question 8 - How long did Messi play for Barcelona?\n",
      "\n",
      "\n",
      "Answer is :  Messi played for barcelona for five years.\n",
      "____________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for n in output['questions']:\n",
    "    count = count+1\n",
    "    list_of_choose = n['options'] + [n['answer'] ]\n",
    "    sample_list = random.sample(list_of_choose,k=4)\n",
    "    inp = {\n",
    "        \"input_text\" : n['context'] ,\n",
    "        \"input_question\" : n['question_statement']\n",
    "    }\n",
    "    print(\"Context is : \",n['context'])\n",
    "    print(\"\\n\")\n",
    "    print(f\"Question {count} - {n['question_statement']}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    context = inp[\"input_text\"]\n",
    "    question = inp[\"input_question\"]\n",
    "    input = \"question: %s <s> context: %s </s>\" % (question,context)\n",
    "    \n",
    "    encoding = tokenizer.encode_plus(input, return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "    greedy_output = model.generate(input_ids=input_ids, attention_mask=attention_masks, max_length=256)\n",
    "    Question =  tokenizer.decode(greedy_output[0], skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    output_2 = Question.strip().capitalize()\n",
    "    \n",
    "    print(\"Answer is : \",output_2)\n",
    "    print(\"__\"*62)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
